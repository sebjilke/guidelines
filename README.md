# Experimental Reporting Guidelines for Experiments in Public Management, a Checklist

>[James, O., Jilke, S. &amp; G. Van Ryzin. 2017. *Experiments in Public Management Research: Challenges and Contributions*. Cambridge: Cambridge University Press](https://www.cambridge.org/core/books/experiments-in-public-management-research/8DB826A84D228568AAEC69732C72F1EC) (pages 509-511).

Below are a series of questions and recommended issues that experimental researchers in public administration and management may want to address when reporting their experimental studies.  The checklist is based on James, Jilke and Van Ryzin (2017), but synthesizes and extends reporting guidelines for experiments from the social and medical sciences.<sup>1</sup>

### 1. Hypotheses and theories they are drawn from
#### a. Specific objectives and hypotheses
i. *What questions was the experiment designed to address?*<br/>
ii. *What specific hypotheses were tested? (e.g., the causal factor estimated, the expected sign and magnitude of expect effects on outcomes, and whether expected effects are expected to be homogenous or to vary by subgroups.)*


### 2. Methods
#### a. Subject recruitment
i. *What was the exact setting and location of data collection? (e.g., a laboratory room at a university, online survey)*<br/>
ii. *Recruitment date(s)? (including follow-ups)*</br>
iii. *Any eligibility or exclusion criteria for subjects?*</br>
iv. *How (and by whom) were participants recruited and selected? (e.g., recruitment by researchers, survey recruitment firm)*</br>
v. *Response rate (if applicable)?*

#### b. Design
i. *Specific experimental design? (e.g., parallel, factorial, conjoint, within or between subjects)*

#### c. Treatments
i. *Is there a detailed description of treatments? (e.g., provide all materials in main text or an appendix or supporting documents.)*<br/>
ii. *Was a control and/or placebo group used?*<br/>
iii. *Which method of treatment delivery was used? (e.g., pen-and-paper, computer, smartphone, face-to-face, telephone)*

#### d. Randomization
i. *Which method and software were used to generate the randomization sequence?*<br/>
ii. *What type of randomization was used? (e.g., clustered, blocked assignment)*<br/>
iii. *What was the unit of randomization? (individuals, households, organisations)* <br/>
iv. *Were participants, those administering the manipulations, and those assessing the outcomes unaware of condition assignment (i.e., blinding)?*<br/>
v. *Was the allocation process followed correctly? (e.g., substantial imbalances of characteristics of across groups can play a role in revealing failures of implementation)*

#### e. Outcomes
i. *What were all the compiled outcome measures?*<br/>
ii. *Is a full questionnaire provided in the appendix for outcomes measured by a survey (if applicable)?*<br/>
iii. *How and when were outcome measures collected?*

#### f. Sample size
i. *How was the sample size of the experiment determined?*<br/>
ii. *Have any stopping guidelines been used for the recruitment of subjects?*


### 3. Results
#### a. Participant flow
i. *Is there a CONSORT participant flow diagram? (This diagram sets out the sampling of experimental participants, the allocation and delivery of treatment, and any attrition; if space precludes, a diagram in the published paper, these details should be provided elsewhere,)

#### b. Confirmatory of exploratory?
i. *Does discussion of the results state clearly which of the outcome measures and subgroup analyses (if any) were determined prior to the conduct of the experiment and which are the result of exploratory analysis?*

#### c. Statistical analysis
i. *Is there a report of sample means and standard deviations (or proportions) of all experimental conditions for intention-to-treat analysis (the entire collection of subjects, whether or not the treatment was successfully delivered to them) prior to any further analysis?*<br/>
ii. *Is there any attrition? If yes, is there a discussion of reason(s) and examination if attrition is conditioned on treatment?*<br/>
iii. *Any other missing data?*<br/>
iv. *Any weighting procedures used?*<br/>
v. *Is any other statistical analysis of the data explained and justified?*


### 4. Other information
i. *Was the experiment reviewed and approved by an institutional review bard/ethics committee?*<br/>
ii. *Was an experimental protocol registered prior to the conduct of the study? If yes, where can the preregistration be accessed?*<br/>
iii. *Did the design/ analysis of the experiment deviate from the preregistration protocol (if applicable)? If yes, why?*<br/>
iv. *If a replication dataset (and/or code) is available, is it available publicly? (e.g., provide a URL)


## Footnotes
<sup>1</sup> Boutron, John &amp; Togerson (2010); Altman &amp; Moher (2010); Gerber et al. (2014).


## References
tba
